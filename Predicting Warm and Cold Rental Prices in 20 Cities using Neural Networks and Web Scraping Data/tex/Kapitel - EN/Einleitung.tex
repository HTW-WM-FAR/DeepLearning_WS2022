\chapter{Introduction}\label{chap:Einleitung}
	Web scraping is a method of automatically extracting data from websites. This is done with the help of programs or scripts that analyze the HTML code of a website and extract specific data. In this seminar paper, data from Immonet.de for 20 different cities was extracted automatically. Information such as the cold and warm rent, as well as other data such as the condition or the type of property are available. The chapter \ref{sec:Webscraping} briefly discusses the topic of web scraping and the problems that arise in the process. The analysis of the data and the search for outliers is discussed in the chapter \ref{sec:Datenanalyse}.  Two different benchmark models are developed: a linear regression and a decision tree using gradient boosting (xgboost).  The linear model is briefly discussed in \ref{subsec: lineare Regression}, xgboost in \ref{subsec: xg}. These models will serve as benchmarks to verify whether the third model - the main part of this seminar paper - the neural network provides a better prediction for the cold and warm rents.  The programming language of this seminar paper is R and the neural network is created using the package 'neuralnet'. The choice of parameters and the adaptation of the neural network are not always clear, so in this elaboration a performance test is performed in parallel and different parameters are compared. At the end a bootstrap aggregation and an analysis of the predicted intervals is done.

